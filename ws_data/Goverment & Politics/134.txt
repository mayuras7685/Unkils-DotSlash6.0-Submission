Discussion of this month’s question devolved into a debate about the usual issues:  privacy versus security, Apple versus the FBI, citizens versus their government.  These are important issues, to be sure.  As Aughlin put it, “Remember, if you lose personal liberty and privacy, you lose everything.  Be very careful what you would wish for in the cause of ‘national interest’.”  Commenting that it requires some subtlety to get this balance between security and privacy right, Jim Dyer argued, “I am frustrated by the idea that we must all accept some ‘new era’ in which privacy is gone… Being able to discuss, with a trusted friend at least, is the kind of freedom that makes us a great county.  Giving up this right is a very bad idea.” On the other hand, Tinashe Madakadze observed, “Privacy should be protected when it serves the good of society, but if it’s used as a tool to deny the FBI its right to obtain access to critical information, it’s ridiculous.”  Taking a more pragmatic tack, Mark observed  “this phone was issued to the guy--and therefore belonged to the city.  So perhaps the claim of privacy to the terrorist is moot.” Several addressed the more specific issue of Apple’s dispute with the FBI.  The question of what a government can demand in a democracy roughly split respondents down the middle.  Taking Apple’s side, ZBV said: “The ability to conscript our labor is limited to Congress… Any ‘compromise’ essentially demands acceptance of a massive expansion & transfer of a conscription power which is currently limited to Congress and not available to any government agency.”  ZBV may have been responding to a comment by superf88 that, “Apple’s right to share with ‘strategic partners’ the user’s application for commercial credit … and other data points (is) right there on the first page of the Apple user contract--there for all to see.  It would seem that this privacy gate is down for the FBI alone.” Slcharles proposed that, “It seems that an equitable solution may be for Apple to say ‘give us the phone and we’ll open it for you, but won’t tell you how we did it.’” While this debate was taking place and the standoff between Apple and the FBI migrated into the courts, we have been getting almost daily updates about efforts to crack the Apple phone in question.  The issue has apparently brought any number of hackers out of the woodwork offering to help the government unlock the phone.  Whether or not it is inevitable that one of them will be able to do it was at the heart of the issue posed in this month’s column.  In that spirit, ChuckB said, “Scott McNeely, former CEO of Sun Microsystems, is a futurist who had it right: ‘Privacy?  Get over it!” Did Scott McNeely have a point?   Has the issue been rendered moot by the very nature of information technology itself and the possibility that developers of security devices are losing the race to those whose capabilities enable them to unlock such devices?  Is our current discussion of infotech security versus privacy a waste of time? What do you think? The red hot legal dispute between Apple and the US government over whether Apple can be compelled to dismantle a cleverly designed product security feature so authorities can access contents on an alleged terrorist’s iPhone has generated a vigorous debate with daily developments.  As they say, this is a big deal.  It raises critical questions. Apple argues that doing what the FBI demands would potentially endanger the security and privacy of its users around the world. The law enforcement agency counters that its interest is strictly in this case.  For those who may have just returned from a jungle trip, out of touch with the news, here’s what apparently is happening in a nutshell, admittedly from a layman’s viewpoint.  The Apple phone is designed with a security feature that makes it difficult for an unauthorized user to get to the contents. A four-digit code controls access. Ten incorrect attempts to open it—whether by a thief, a terrorist, or an FBI agent--triggers an action that destroys the contents.   From the FBI’s view, Apple is in position either to identify the four-digit code (the company disputes this) or it can turn off the 10-attempt limit, which would allow law enforcement to crack the code over time (also in dispute). Apple’s management has, at least initially, refused the government’s order and subsequent lawsuit on the grounds doing so runs the risk of making public the workings of a device intended to serve the security interests of its users.  This event has further fueled the ongoing global debate over issues of privacy and security associated with information technology.  But what if the debate has been rendered academic by the very nature of information technology innovation itself?  Can the following argument be made:  Information technology is rendering moot the possibility of maintaining security and privacy in a society.  Locks, be they analog or digital, can be picked.  Whether Apple agrees to open the phone or not, it will be cracked by someone if the motives for doing so are strong enough to justify an investment in the necessary technology.  What technology locks, it can just as effectively unlock.   George Orwell’s vision of Big Brother in 1984 may be late arriving, but it is here. This point of view can be summed up by these words: In today’s world, the only assurance of security and privacy is a promise made verbally by a person who will honor it. If this argument has any validity, it raises further questions.   Is Silicon Valley deceiving itself in thinking that security and privacy in the use of its products can be preserved?   Is Apple’s refusal to unlock the phone, as important as it is to its business future, anything more than an effort to delay the inevitable and designed to show customers that it tried to defend their security and privacy?  

In other words, is Apple’s real challenge information technology innovation itself? What do you think?  