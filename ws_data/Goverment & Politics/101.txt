In the wake of a rancorous presidential election and the early, tumultuous days of the Trump administration, a new book by HBS professor David Moss—Democracy: A Case Study—serves as a reminder of that one word’s living, breathing origins. In a collection of 19 case studies, Moss examines key institutions and decision points of American democracy that range from the drafting of the United States Constitution to a consideration of campaign spending through the Citizens United court case decided by the Supreme Court. Underlying it all is the recognition that conflict is a constant and necessary force in maintaining a healthy democracy. Less clear, says Moss, is when conflict tips from productive to destructive—yet it’s necessary to worry about how and when that might happen. “What struck me in working on these cases is that in nearly every moment of American history, people thought democracy was about to break,” Moss says. “In one instance—the Civil War—they were right.” But most of the time they were wrong, Moss continues, in part because they acted, became more engaged, and worked for reforms. “Their hypochondria, if I can call it that—their repeated fear that democracy was sick—was ultimately good for the political system because it promoted action and engagement.” The book opens with a turning point in the country’s history, after America had won its War of Independence with Great Britain but before the adoption of the US Constitution. Governed by the Articles of Confederation, the young country was wrestling with the balance of power between federal and state governments. Moss sets the scene: “Under the Articles, the federal government was very weak—there was no president or Supreme Court. Congress had very little power and couldn’t even levy taxes. Each state had one vote, and a supermajority was required for most important decisions. Unanimity among the states was required to amend the Articles themselves.” The states, he continues, had most of the power, which worked well enough when the colonists were rebelling against Britain. Now, in the mid-1780s, it felt as if the country was coming apart. “There was a real concern the country could fail,” Moss says. James Madison retired to his estate—a slave plantation—and asked Thomas Jefferson for books about confederacies and republics since ancient Greece. “He came to the conclusion that weak confederacies rarely succeeded and that the most fundamental challenge of a representative democracy was how to navigate between empowering the majority on the one hand and limiting the majority, so as to protect the rights of the minority, on the other.” Believing that tyranny of the majority was more likely in a smaller democracy, Madison and several other delegates argued for a “federal negative” at the Constitutional Convention of 1787 that would give Congress veto power over state laws. The case provides contextual detail for the debate, outlining why some—having just defeated a monarchy—might be leery of empowering a central government. And, in classic case method style, it concludes on a decision point: Will Congress have veto power over state laws? And more broadly, how much power should the federal government have over individual states? It’s a question that would continue to play out throughout the country’s history (and on into today’s headlines) under a wide variety of circumstances. “By debating that relatively narrow proposal for a federal negative, students are forced not only to deal with the fundamental tension between majority rule and tyranny of the majority, but also to focus on the essential balance of power between the states and the federal government—and to actively consider what that balance should look like in practice,” says Moss. The answer isn’t always as obvious as it seems. In another case, a newly-elected President Lincoln must decide whether or not to resupply Fort Sumter, located in South Carolina, a state that seceded from the Union shortly before Lincoln took office. South Carolina will not allow the resupply; should Lincoln use force to make them comply? “The larger question is, should he allow South Carolina and other rebellious states to secede?” asks Moss. “At first the students say no, of course not. But then many students start having second thoughts when they begin to consider how costly the war could be in both lives and money and when they remember that Lincoln wasn’t proposing the abolition of slavery at that time. Before long, there’s a real debate about what Lincoln should do—should he resist secession or just accept it and move on? Ultimately, it raises the question of what it means to have a national democracy—can pieces of it depart, or not?” Readers of Democracy grapple with the same questions; an appendix provides a follow-up of what happened. However, Moss encourages readers to discuss the cases in groups (including local book groups) whenever possible—ideally with at least some people who don’t share your political beliefs. “These cases remind us of how much we can disagree on an issue, but also how much we had, and continue to have, in common,” he says. “Sometimes I think we get so wrapped up in the details of a current debate—whether it concerns health care or taxes or the size of government—that we lose track of what we most have in common, which are the democratic values and principles that make our system of government work. In the end, it’s what we have in common that makes productive conflict possible.” “Obviously there are many challenges and anxieties right now,” says Moss, “but it’s precisely by acting on those anxieties in a constructive way that our democracy will be safeguarded and strengthened.” Democracy offers plentiful evidence of how that work happened in the past, while bringing the system’s struggles and fragility into bold, compelling relief. Moss developed the case studies in Democracy for a course open to Harvard undergraduates and MBA students. First taught in the fall of 2013, it has been oversubscribed ever since; students even took the cases back to their high school history teachers, urging them to try out the approach in their own classrooms. That grassroots effort led to the creation of a pilot to make the teaching materials, and a two-day training program in the case method, available to interested high school educators. (The program has engaged 40 schools in eleven states to date.) Business Research that Makes for Smarter Public Policy
The Role of Government When All Else Fails As the cases presented here will reveal, democracy in America has always been a contact sport. Words like “cooperation” and “consensus” may sound appealing and even comforting, but American democracy has survived and thrived from one generation to the next on the basis not principally of harmony but of conflict—sometimes intense conflict—mediated, generally, by shared ideals. Indeed, democratic decision making in the United States has nearly always been rooted in disagreement and tension, including plenty of bare-knuckle politics. The nation has witnessed sharp partisan, ideological, and often sectional conflict in everything from the battle over ratification of the Constitution in 1787–1788 to the repeated fights over a national bank (in the 1790s, 1830s, and 1910s) to the bitter struggles over health care and gun laws today. Intense political conflict has always been with us and is, in fact, profoundly American. The critical question is what makes this conflict either constructive or destructive. Indeed, this is the central question of this book. Political conflict is not a disease, as some pundits contend, but instead an essential feature of American democracy. In most periods across the nation’s history, it has served as a powerful source of strength. But not always. And this, in a nutshell, is what we need to figure out. Why has fierce political conflict proved highly constructive at many historical moments and severely destructive at others, and which type of conflict—constructive or destructive— characterizes the nation’s democracy today? We’ll return to this question shortly. First, though, it is worth taking a closer look at the idea of democracy itself. If you ask family members or friends what democracy is, they are likely to begin by saying that it is a system of government in which people cast votes for representatives and in which laws are determined by majorities. It is also possible that some of them will distinguish representative democracy (also known as republican government) from the type of direct democracy practiced in a New England town meeting or in ancient Greece. If you give them a bit more time and you’re having the discussion in the United States, they will likely tell you about the three branches of government as set out in the Constitution, about the checks and balances between these branches, and possibly about the importance of individual liberty and the various protections written into the Bill of Rights. Occasionally someone may warn that not all of these things are quite as straightforward as they seem—that majorities don’t always get their way, for example—and this is where the conversation will start to get interesting. James Madison suggested back in the mid-1780s, when he was contemplating the creation of a new constitution for the young nation, that the “majority who rule” in a representative democracy are ideally “the safest Guardians both of public Good and of private rights.” Yet he also recognized that representative democracy inevitably confronts two foundational problems. The first is that elected representatives may end up deferring to powerful special interests rather than to their constituents, and in this way majority rule may be subverted as special interests gain control of the policymaking process at the expense of the “public Good.” By the twentieth century, this sort of special interest influence was sometimes referred to as “capture,” indicating that special interests could be so powerful as to effectively capture public officials for their own benefit. The second foundational problem, which Madison regarded as even more dangerous than the first, is that majorities, when they do exercise power in a democracy, are liable to oppress or tyrannize minorities, violating those minorities’ “private rights.” A dominant religious group, for instance, might use its power in the political system to persecute smaller religious groups. When this happens, legitimate majority rule is not subverted or captured by special interests but instead perverted by the passions of the majority itself. The core challenge of democracy, as Madison saw it, was to empower the people to select their lawmakers while somehow avoiding these twin evils, special interest capture of government on the one hand and tyranny of the majority on the other. Particularly fearful of the latter, he came to see conflict—continuous political struggle across a multitude of widely dispersed factions—as the key to preventing tyrannical majorities from forming. His formula was far from foolproof, allowing numerous majoritarian abuses over the course of the nation’s history, including the most horrific of all, slavery, which Madison himself participated in. The more difficult question is not whether it was foolproof—nothing in human affairs ever is—but instead whether it was better or worse than the alternatives. We’ll have a chance to examine Madison’s conception of a healthy re- public in detail in Case 1. For now, however, it is enough to highlight three core elements of his understanding of democratic governance: first, that democracy is inherently fragile, likely to be subverted by special interests or perverted by majority passions unless the proper checks and balances are in place; second, that the necessary checks and balances extend far beyond the formal structures of government, such as the three branches that Madison would play a large role in designing at the Constitutional Convention in 1787; and finally, that political conflict—at every level of society—is central to a vibrant democracy. Successfully building and sustaining a democracy, in other words, is about much more than simply ensuring broad suffrage and majority rule, although both are vital. Nor is it enough to provide a compelling blueprint, like the one crafted at the Constitutional Convention in Philadelphia, which specifies formal governing structures and the rules of the game, although this too has proved to be an essential feature of American democracy. Equally necessary, it seems, is a vibrant spirit of political engagement among the people themselves that yields productive conflict in the marketplace of ideas, presumably along the lines Madison envisioned. If so, this brings us back to the question of what separates constructive political conflict from destructive political conflict in a democracy. Unfortunately, there exists no perfect theory or framework that we can rely on in answering this question. We can draw lessons from historical examples, however, on both the positive and the negative sides. The Civil War—by far the most violent episode in the nation’s history—provides a natural starting point. Needless to say, the lead-up to the Civil War represents a powerful example of destructive conflict in American politics. Although there was plenty of political tension in the late 1850s and the start of the 1860s, very little of it was in any way constructive. But why, exactly? In February 1861—not long after Lincoln had been elected president and Southern states had begun to secede from the Union, but before Lincoln had taken the oath of office—the editor of the Atlantic Monthly, James Russell Lowell, suggested that political tensions had turned destructive in the United States because Americans had come to take effective self-governance for granted. He claimed that the Southern secessionists, in particular, had given up on the idea of national democracy altogether: they now question the right of the majority to govern, except on their terms, and threaten violence in the hope of extorting from the fears of the Free States. . . . Their quarrel is not with the Republican Party, but with the theory of Democracy. Most secessionists continued to believe in the application of democratic procedures at the state level (at least for white men), but apparently not at the federal level. When Lincoln won the election in November 1860, many Southerners—perhaps a majority—were unswayed by the fact that he had secured more votes, both popular and electoral, than any other candidate. In their eyes, he was illegitimate because he opposed the expansion of slavery. So perhaps conflict in American politics turned destructive when common faith in the democracy itself broke down and could no longer hold Americans together. Fortunately, the rupture that occurred in the early 1860s was very much the exception, not the rule, across the nation’s history. In nearly every other period, conflict was a given, but a shared belief in democratic self-governance helped channel that conflict in constructive directions—or, at the very least, helped prevent partisan conflict from degenerating into violence. As readers make their way through the cases that follow, they will see this dynamic of productive tension play out again and again, in a host of different contexts. In some cases they will observe controversial policies gaining acceptance through appeals to democratic process or principles. Sev- eral years after the Panic of 1837, for example, budget hawks in New York State proposed a constitutional provision that would severely limit lawmakers from authorizing public borrowing, but with a democratic escape hatch allowing state debt to be issued so long as voters approved it in a state-wide referendum. At roughly the same time, education reformers were calling for a significant expansion of government spending to fund “free” schools, arguing that public education was essential not only for building a more capable workforce but also—and perhaps most importantly—for ensuring a more informed and responsible electorate. On both ends of the political spectrum, therefore, political actors tied controversial proposals to core democratic values. Significantly, as we will see in Cases 6 and 7, New York lawmakers of the 1840s considered both of these proposals nearly simultaneously—fiscal retrenchment on the one hand, and fiscal expansion to support public education on the other. This sort of dissonance was not uncommon in American politics. Instead of meeting in the middle or splitting the difference, two competing factions or parties frequently both secured what they most wanted. It was a distinctive form of compromise, with the classic American example being the so-called Great Compromise, proposed by the illustrious Connect- icut delegation at the Constitutional Convention in 1787. As the convention debated how Congress should be structured, delegates from large states insisted that representation ought to be proportional to population, whereas those from small states favored equal representation by state, irrespective of population. Instead of meeting in the middle (for example, by adopting a proportional model weighted somewhat toward small states), delegates from both sides agreed to a two-part solution: proportional representation in the House and equal representation in the Senate. Each side, in other words, achieved its preferred option, but had to tolerate the other side also getting what it wanted. Such horse-trading could be explicit, as it was in the Great Compromise, or it could be implicit or even coincidental, as in New York in the 1840s. Either way, it was indicative of the productive tension that so often characterized American politics. From a policy perspective, vigorous political conflict—especially when rooted in shared democratic ideals—thus had the potential to surface good ideas from all sides, generating a best-of-both dynamic where lawmakers might pick the best from Column A and the best from Column B. The author F. Scott Fitzgerald famously wrote that the “test of a first-rate intelligence is the ability to hold two opposed ideas in the mind at the same time, and still retain the ability to function.” By this standard, the institutions of American policymaking must be judged to have been rather ingenious, at least across much of the nation’s history. Conflicting ideas, interests, and policies, not ideological consistency, have long been the stock and trade of American politics. But the logic of what I call productive political tension also runs deeper, beyond policymaking to the very foundation of democratic governance itself. Productive tension between competing factions serves not only as a vital source of diverse policy ideas, but also as a critical check on democratic excess, as Madison observed on the eve of the Constitutional Convention. Indeed, the paramount role of productive tension in American politics is apparent throughout the nation’s history and, consequently, in all of the case studies that compose this volume. The words “productive tension” appear nowhere in the Constitution, of course, nor is there any certain recipe or formula for creating and sustaining it. But it is no less important, as a result. It is, in short, one of the intangibles of American democracy, which breathes life into the republic in the most mysterious of ways, animating an other- wise static set of structures and rules as powerfully—and as subtly—as the oxygen carried in our bloodstreams. Excerpted from Democracy: A Case Study by David A. Moss, published by The Belknap Press of Harvard University Press. Copyright © 2017 by the President and Fellows of Harvard College. Used by permission. All rights reserved.  