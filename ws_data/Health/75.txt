Brian Kenny:  The drug Thalidomide, prescribed to pregnant women in the late 1950s to alleviate morning sickness, caused thousands of infants to be born with malformed limbs, only 40 percent of whom survived infancy. It was by no means the first drug to cause harm to patients but, in the dawn of the age of television, it was among the first to have those ill effects broadcast to the world. Although the drug was never approved for use in the United States, it led to the passage of the Kefauver Harris Amendment, which required drug manufacturers to provide proof of the efficacy and safety of their drugs before approval.  That sounds like a reasonable requirement with all the right intentions, but critics say it may have cost more lives than it saved. Prior to the amendment, it took an average of seven months for a drug to get approved by the Food and Drug Administration. Today, it takes anywhere from 10 to 12 years, which is far too long to help most patients with life-threatening illnesses. What can be done to improve the model for drug testing, and approval without putting patients’ safety in jeopardy?  Today we'll hear from professor Ariel Stern about her case entitled, Adaptive Platform Trials: The Clinical Trial of the Future?.  I'm your host Brian Kenny, and you're listening to Cold Call.  Ariel Stern's research focuses on the management of innovation and health care with an emphasis on medical devices and pharmaceutical industries. She is particularly interested in the intersection of the regulation, firm strategy, and economics of health care, all of which I think factor into this case. Ariel, thanks for joining me today.  Ariel Stern: 	Thank you so much for having me, Brian.  Kenny:  Maybe you can start by setting up the case for us. Who is the protagonist and what's going on?  Stern:  This case is set in the summer of 2017, and our protagonist is Dr. Brian Alexander, who is a radiation oncologist at the Dana-Farber Cancer Center here in Boston. He's also an associate professor at Harvard Medical School. Brian is in the process of launching a new type of clinical trial, an adaptive platform trial. Where we come in is a point in time where some of the leading experts in the country have already had their input on the study design, which is quite innovative, but the business model itself is still developing, and so that's where it makes a terrific HBS case.  Kenny: 	I'm wondering what prompted you to write this case? Do you have a background in medicine, or an interest in medicine?  Stern:   I started off as an undergraduate studying biochemistry, so I have been interested in the life sciences for quite a while. My first interest in clinical trials, in particular, dates back to 2004, when my mother was diagnosed with cancer and was enrolled in a clinical trial for an experimental cancer therapy. It took us between two and three years after she'd finished her course of treatment to learn that that drug didn't really have a long-term effect [on her type of cancer]. That was quite disappointing, and at the time it really struck me that surely there must be a way to get this information more efficiently. This was before I had a PhD, and before I'd thought deeply about clinical trial design.  The more immediate answer is that through the Harvard MIT Center for Regulatory Science that I work with closely, I've had the opportunity to work with Brian Alexander, our protagonist. And broadly, I am  broadly excited about all the great work being done in clinical trial innovation here in Boston.  The other thing that led to the case is that it dovetails really nicely with the work of the Kraft Precision Medicine Accelerator here at HBS. The confluence of all of those factors, really meant that this was a great time to write a case about clinical trial innovation.  Kenny: 	Because the case centers around clinical trials for glioblastoma, just tell us quickly what that is.  Stern:  Yeah, so unfortunately glioblastoma is a malignant and fast-growing form of brain cancer. It's relatively uncommon—it affects about 12,000 people in the United States every year, but that's actually far less common than a lot of the cancers that we hear about. The typical course of treatment for patients is also unpleasant. It involves brain surgery to the extent possible, followed by a course of chemo and radiation. Despite that, there are very frequent recurrences.  The prognosis is not good; the five-year survival rate for folks diagnosed with glioblastoma is in the single digits. So this is really quite a serious disease, and one where there's a lot of public and individual enthusiasm for doing better by our patients.  Kenny: 	It's a complicated landscape, but how do drugs get approved in the US?  Stern:  In a nutshell, as you mentioned in your introduction, the entire process can easily take over a decade. We think about 10 to 12 years from start to finish. Drugs start off in laboratories, in universities, in pharmaceutical companies in what we call the preclinical phase of research, where we're trying to understand how the drugs work, and if they'll work in patients before we start giving them to patients. In order to start giving drugs to patients, the drug’s sponsor, which is typically a pharmaceutical company, will file what's called an investigational new drug application with the FDA in the United States.  If approved, they get the green light to move ahead with clinical trials, and that's followed by what we call the clinical trial phase, that involves usually three phases of clinical trials. We can go into more detail if you'd like...  Kenny: 	It's not cheap, right?  Stern: 	It's not cheap. Estimates really vary on this one, and as you can imagine, the costs are likely to vary. If you're dealing with a more severe disease where regular hospitalizations are necessary, the cost of clinical trials will certainly be much higher, but on average we're talking about anything from hundreds of millions of dollars to well over $1 billion to develop a new drug. So this is serious money.  Kenny:  That gets to issues that we've heard about  where there's concern that pharmaceutical companies are only investing to research drugs that are going to pay off at the end, meaning drugs that treat conditions that affect many people, versus a few, like in the case of glioblastoma.  Stern:  Absolutely, and we have in health care economics a number of good studies that have actually shown precisely that. Without getting ahead of ourselves, I think that one of the concerns is that for relatively rare cancers we are worried that because the potential market is small on the backend, we may not have as much research as we would otherwise see for much more prevalent diseases.  Kenny: 	There's a lot of room for improvement, a lot of room for business solutions maybe, and we'll get to those in a little bit. Another definition here: Can you describe a randomized controlled trial?  Stern:  This is the current method and ... it hasn't evolved much since it was conceptualized. The original randomized controlled trials, or RCTs, go back exactly 70 years to 1948 believe it or not, when we did the first randomized controlled trials of streptomycin, in tuberculosis patients. There's of course been a good deal of evolution in statistical software, but more or less the design has been unchanged. We often think about a traditional randomized controlled trial as having two arms, so a treatment and a control arm, which is something a lot of folks will be familiar with.  What we do is pre-specify the number of patients that are going to be needed to get statistically meaningful results out of this trial, and then what we do is randomize patients into either the treatment arm, where they would get some sort of experimental therapy, or the control arm, where they would typically get a placebo. Now, we don't use placebos in cancer trials for the obvious reason that it would be pretty unethical, so in cancer trials what we usually do is compare an experimental therapy to what we call the standard of care, typically the best available treatment for patients with that cancer. Then we randomize patients into each of the control arms and compare outcomes. Kenny:  You spent a lot of time in the case describing the difference between statistics. , like what kind of statistics they look at, Can you explain that, because it's important when you get into the adaptive trial platforms.  Stern:  Frequentist trials are those that basically set everything up in advance, and in a sense let it run, let it rip. Traditional randomized controlled trials are frequentist trials. We do some statistical calculations up front, and we say, "Look, if we're expecting this type of effect from this drug, this is roughly how many patients we'll need to give it to, in order to observe a statistically significant difference between treatments and control groups."  Bayesian trials, which are the basis for adaptive platform trials, are a little bit different. What Bayesian trials do is incorporate information as it accumulates. I'll give you an example. Say patients with a certain tumor type are doing incredibly well on a given therapy. We can incorporate that information into how we assign patients to receive that therapy, and that'll work into the adaptive platform design.  Kenny: 	That also addresses the issue we just talked about, which is if you happen to be on the wrong arm of the study, then this gives you an opportunity to move?  Stern:  What Bayesian randomization allows us to do is maintain the statistical rigor that we want from trials, and really leads to causal inference, which is quite important. It allows us to be smart about the size of the sample we're using, and how we're assigning patients.  Kenny: 	So now let's get to the meat of the case, which is the adaptive platform trial. Can you describe that in contrast to the randomized controlled trial?  Stern:  There are two components: the adaptive component and the platform component. Both are uniquely important in this trial design. Let's start with the platform, since I think it's simpler, and conveniently Brian, we have names that start with A and B, so we're going imagine that we each have an experimental therapy. I have experimental therapy A, you have experimental therapy B. In the traditional clinical trial world, what would happen, is let's say experimental therapies A and B are both for small cell lung cancer.  You would go out and enroll your trial, and I would go out and enroll my trial. We'd both have a control arm of patients who are not going to get this experimental therapy, either yours or mine. We would both hire a contract research organization to help us run the trial. We'd pick an IT provider, we'd find patients, and do all of that. Let's just say for simplicity that we both determined that we need 80 patients to get statistical significance in our trials.  You're going to have 80 patients, I'm going to have 80 patients. You'll put 40 of your patients on your experimental therapy, 40 will be on the control. I'll do exactly the same. In that world, in order for you to get an answer about whether or not your drug works in these lung cancer patients, and for me to get an answer, we'll need a total of 160 patients.  What the platform trial does builds on this insight that if we can get it together in advance to coordinate on a lot of aspects of the trial infrastructure, we can actually share a control arm. If we jointly choose a contract research organization that's going to go out and help us recruit patients, and if we jointly choose an IT provider, and IT systems, we can silo off our individual information about the actual experimental therapies we're studying, and share a control group of patients.  Now, without doing anything else, we have just gone from needing 160 patients in total for us both to get statistical significance, to needing 120 patients. The sample size has decreased. We're seeing efficiencies, especially in uncommon cancer where it's often hard to find these patients; 40 percent of cancer trials never fully enroll.  Then, we can layer on top of that setup what we call Bayesian adaptive randomization. That's a mouthful, but what that means is that we're actually using Bayesian statistics that have been pre-specified for this trial, to figure out how to efficiently assign patients to different arms of the trial. Go back to my example from before. We have patients with a certain tumor type, and we learned that they are doing incredibly well on your therapy, on therapy B, based on interim analysis, so about once a month we're going to actually look at the data, and see how patients are progressing.  We say, "Wow, patients of this type are doing really well in Brian's therapy." We can use our pre-specified algorithm to now preferentially assign that type of patient to your arm of the trial. Patients love this. As the trial progresses, patients are not only being used efficiently, because of the shared control arm component of the trial design, but we've also got the patients that are coming in being preferentially assigned to the treatment arm of the trial they're most likely to benefit from.  Kenny: 	So we've gotten efficiencies, we've got better patient outcomes, those are two great things. What are some of the other benefits that emerge from using the adaptive platform trials? Stern: 	So thinking back to my mother’s experience, the other thing we get is faster information on what won't work. This is quite important and something we don't talk about enough. What Bayesian adaptive platform trials allow us to do, as we talk about trial arm stopping, and graduation. Graduation means that we learn very quickly that a trial's very effective, and we can move that drug onto the next phase. Stopping means that we also learn efficiently if a particular therapy isn't going to work for a group of patients. Surely it's desirable to stop researching that drug in that group of patients if we have a very good statistical signal that it's unlikely to help them.  Kenny:  Let's dig into some of the business challenges. I was fascinated reading about just how many people are involved in this, and some of the really difficult business challenges that they faced in trying to get the trial up and running. Can you talk a little bit about that?  Stern:  If you read between the lines in the case, what you'll see is that putting together just this one trial involved over 130 oncologists, pathologists, radiologists, and statisticians. This is a massively collaborative effort... Kenny: 	There was some real entrepreneurial thinking needed about how you fund something like this. They came up with some very interesting ways on how to fund it.  Stern:  One of the benefits of an adaptive platform trial is that we set up the infrastructure once and then can continue to add experimental therapies to the trial. But that's costly, because we're building infrastructure for something that hopefully will last for many years, if not decades, until we have good treatments for glioblastoma. What that means is the upfront costs are massive.  We have a lot of traditional financing options, looking at things like asking pharmaceutical companies, who typically fund clinical research anyhow, to pay for individual arms of the trial. But, the upfront costs are still quite an obstacle. In this case, the folks running the trial decided to start a foundation. The foundation is called, "The Global Coalition for Adaptive Research." Through this foundation, they were able to start negotiating relationships with contract research organizations, and only then, start to approach pharmaceutical companies and other cancer research groups to think about how they might want to be involved financially.  Kenny: 	I was particularly interested in the notion of them becoming a health care provider. That was really innovative.  Stern:  While there's this really daunting upfront challenge in financing, there are a number of new opportunities created here as well. One of the insights that Brian Alexander has had in thinking about this is why not provide all of the health care for glioblastoma patients. We've got folks coming in anyhow, they're going to be seeing experts in both medical and radiation oncology anyhow, why not just outsource all of the care for those patients to one of these trial sites and try to capture some of the value for patients and providers in that way. So that was one idea.  The cost of doing a trial in glioblastoma for other experimental cancer therapies will go down once this platform exists. You could also get really creative—this is HBS, after all—with thinking about other things that we might do. Just one example is that there are a lot of small biotechnology companies that have only one or two experimental cancer drugs, and they've got resources from their funders, typically venture capitalists, to run maybe only clinical trials in one type of cancer.  Now, because we have this foundation behind this research platform, the foundation can approach some of these small biotech companies and say, "Hey look, we think your drug might be interesting to study in glioblastoma. Why don't you give it to us and we'll pay for that arm of the trial. We'll study your drug and if it turns out this drug is effective, we'll have some sort of royalty sharing agreement on the back end." Suddenly, the foundation is able to take on some of the risk and also have a piece of the action if it turns out that these drugs are effective.  Kenny: 	Have you discussed this case in class?  Stern: 	I have. We've had a couple of events—we were able to discuss this at Boston's Hub Week event... And then I also discussed this with a group of HBS Healthcare Alumni a couple of months ago. They loved it. It's interesting t hatthe folks who've worked in pharma have two reactions, very rapidly. The first reaction is, "Wow, this makes so much sense." The second reaction that follows immediately is, "I don't know if these companies will ever go for this." People who have seen what clinical research management looks like right away say, "Oh, this is going to really freak people out, this is so different than how we've been doing clinical research up until now."  I think they're right, but I think that we're all going to be positively surprised.  Kenny: 	Thanks so much for joining us today.  Stern: 	Thanks so much for having me Brian.  Kenny: 	If you enjoyed this episode of Cold Call, please subscribe on iTunes for more cases like this one, and while you're there, please write a review. You can find the adaptive platform trials case in the HBS case collection at hbr.org. I'm your, host Brian Kenny, and you've been listening to Cold Call.  Interview transcript edited for length and clarity. Interview recorded January 26, 2018. Brian Kenny:  The drug Thalidomide, prescribed to pregnant women in the late 1950s to alleviate morning sickness, caused thousands of infants to be born with malformed limbs, only 40 percent of whom survived infancy. It was by no means the first drug to cause harm to patients but, in the dawn of the age of television, it was among the first to have those ill effects broadcast to the world. Although the drug was never approved for use in the United States, it led to the passage of the Kefauver Harris Amendment, which required drug manufacturers to provide proof of the efficacy and safety of their drugs before approval.  That sounds like a reasonable requirement with all the right intentions, but critics say it may have cost more lives than it saved. Prior to the amendment, it took an average of seven months for a drug to get approved by the Food and Drug Administration. Today, it takes anywhere from 10 to 12 years, which is far too long to help most patients with life-threatening illnesses. What can be done to improve the model for drug testing, and approval without putting patients’ safety in jeopardy?  Today we'll hear from professor Ariel Stern about her case entitled, Adaptive Platform Trials: The Clinical Trial of the Future?.  I'm your host Brian Kenny, and you're listening to Cold Call.  Ariel Stern's research focuses on the management of innovation and health care with an emphasis on medical devices and pharmaceutical industries. She is particularly interested in the intersection of the regulation, firm strategy, and economics of health care, all of which I think factor into this case. Ariel, thanks for joining me today.  Ariel Stern: 	Thank you so much for having me, Brian.  Kenny:  Maybe you can start by setting up the case for us. Who is the protagonist and what's going on?  Stern:  This case is set in the summer of 2017, and our protagonist is Dr. Brian Alexander, who is a radiation oncologist at the Dana-Farber Cancer Center here in Boston. He's also an associate professor at Harvard Medical School. Brian is in the process of launching a new type of clinical trial, an adaptive platform trial. Where we come in is a point in time where some of the leading experts in the country have already had their input on the study design, which is quite innovative, but the business model itself is still developing, and so that's where it makes a terrific HBS case.  Kenny: 	I'm wondering what prompted you to write this case? Do you have a background in medicine, or an interest in medicine?  Stern:   I started off as an undergraduate studying biochemistry, so I have been interested in the life sciences for quite a while. My first interest in clinical trials, in particular, dates back to 2004, when my mother was diagnosed with cancer and was enrolled in a clinical trial for an experimental cancer therapy. It took us between two and three years after she'd finished her course of treatment to learn that that drug didn't really have a long-term effect [on her type of cancer]. That was quite disappointing, and at the time it really struck me that surely there must be a way to get this information more efficiently. This was before I had a PhD, and before I'd thought deeply about clinical trial design.  The more immediate answer is that through the Harvard MIT Center for Regulatory Science that I work with closely, I've had the opportunity to work with Brian Alexander, our protagonist. And broadly, I am  broadly excited about all the great work being done in clinical trial innovation here in Boston.  The other thing that led to the case is that it dovetails really nicely with the work of the Kraft Precision Medicine Accelerator here at HBS. The confluence of all of those factors, really meant that this was a great time to write a case about clinical trial innovation.  Kenny: 	Because the case centers around clinical trials for glioblastoma, just tell us quickly what that is.  Stern:  Yeah, so unfortunately glioblastoma is a malignant and fast-growing form of brain cancer. It's relatively uncommon—it affects about 12,000 people in the United States every year, but that's actually far less common than a lot of the cancers that we hear about. The typical course of treatment for patients is also unpleasant. It involves brain surgery to the extent possible, followed by a course of chemo and radiation. Despite that, there are very frequent recurrences.  The prognosis is not good; the five-year survival rate for folks diagnosed with glioblastoma is in the single digits. So this is really quite a serious disease, and one where there's a lot of public and individual enthusiasm for doing better by our patients.  Kenny: 	It's a complicated landscape, but how do drugs get approved in the US?  Stern:  In a nutshell, as you mentioned in your introduction, the entire process can easily take over a decade. We think about 10 to 12 years from start to finish. Drugs start off in laboratories, in universities, in pharmaceutical companies in what we call the preclinical phase of research, where we're trying to understand how the drugs work, and if they'll work in patients before we start giving them to patients. In order to start giving drugs to patients, the drug’s sponsor, which is typically a pharmaceutical company, will file what's called an investigational new drug application with the FDA in the United States.  If approved, they get the green light to move ahead with clinical trials, and that's followed by what we call the clinical trial phase, that involves usually three phases of clinical trials. We can go into more detail if you'd like...  Kenny: 	It's not cheap, right?  Stern: 	It's not cheap. Estimates really vary on this one, and as you can imagine, the costs are likely to vary. If you're dealing with a more severe disease where regular hospitalizations are necessary, the cost of clinical trials will certainly be much higher, but on average we're talking about anything from hundreds of millions of dollars to well over $1 billion to develop a new drug. So this is serious money.  Kenny:  That gets to issues that we've heard about  where there's concern that pharmaceutical companies are only investing to research drugs that are going to pay off at the end, meaning drugs that treat conditions that affect many people, versus a few, like in the case of glioblastoma.  Stern:  Absolutely, and we have in health care economics a number of good studies that have actually shown precisely that. Without getting ahead of ourselves, I think that one of the concerns is that for relatively rare cancers we are worried that because the potential market is small on the backend, we may not have as much research as we would otherwise see for much more prevalent diseases.  Kenny: 	There's a lot of room for improvement, a lot of room for business solutions maybe, and we'll get to those in a little bit. Another definition here: Can you describe a randomized controlled trial?  Stern:  This is the current method and ... it hasn't evolved much since it was conceptualized. The original randomized controlled trials, or RCTs, go back exactly 70 years to 1948 believe it or not, when we did the first randomized controlled trials of streptomycin, in tuberculosis patients. There's of course been a good deal of evolution in statistical software, but more or less the design has been unchanged. We often think about a traditional randomized controlled trial as having two arms, so a treatment and a control arm, which is something a lot of folks will be familiar with.  What we do is pre-specify the number of patients that are going to be needed to get statistically meaningful results out of this trial, and then what we do is randomize patients into either the treatment arm, where they would get some sort of experimental therapy, or the control arm, where they would typically get a placebo. Now, we don't use placebos in cancer trials for the obvious reason that it would be pretty unethical, so in cancer trials what we usually do is compare an experimental therapy to what we call the standard of care, typically the best available treatment for patients with that cancer. Then we randomize patients into each of the control arms and compare outcomes. Kenny:  You spent a lot of time in the case describing the difference between statistics. , like what kind of statistics they look at, Can you explain that, because it's important when you get into the adaptive trial platforms.  Stern:  Frequentist trials are those that basically set everything up in advance, and in a sense let it run, let it rip. Traditional randomized controlled trials are frequentist trials. We do some statistical calculations up front, and we say, "Look, if we're expecting this type of effect from this drug, this is roughly how many patients we'll need to give it to, in order to observe a statistically significant difference between treatments and control groups."  Bayesian trials, which are the basis for adaptive platform trials, are a little bit different. What Bayesian trials do is incorporate information as it accumulates. I'll give you an example. Say patients with a certain tumor type are doing incredibly well on a given therapy. We can incorporate that information into how we assign patients to receive that therapy, and that'll work into the adaptive platform design.  Kenny: 	That also addresses the issue we just talked about, which is if you happen to be on the wrong arm of the study, then this gives you an opportunity to move?  Stern:  What Bayesian randomization allows us to do is maintain the statistical rigor that we want from trials, and really leads to causal inference, which is quite important. It allows us to be smart about the size of the sample we're using, and how we're assigning patients.  Kenny: 	So now let's get to the meat of the case, which is the adaptive platform trial. Can you describe that in contrast to the randomized controlled trial?  Stern:  There are two components: the adaptive component and the platform component. Both are uniquely important in this trial design. Let's start with the platform, since I think it's simpler, and conveniently Brian, we have names that start with A and B, so we're going imagine that we each have an experimental therapy. I have experimental therapy A, you have experimental therapy B. In the traditional clinical trial world, what would happen, is let's say experimental therapies A and B are both for small cell lung cancer.  You would go out and enroll your trial, and I would go out and enroll my trial. We'd both have a control arm of patients who are not going to get this experimental therapy, either yours or mine. We would both hire a contract research organization to help us run the trial. We'd pick an IT provider, we'd find patients, and do all of that. Let's just say for simplicity that we both determined that we need 80 patients to get statistical significance in our trials.  You're going to have 80 patients, I'm going to have 80 patients. You'll put 40 of your patients on your experimental therapy, 40 will be on the control. I'll do exactly the same. In that world, in order for you to get an answer about whether or not your drug works in these lung cancer patients, and for me to get an answer, we'll need a total of 160 patients.  What the platform trial does builds on this insight that if we can get it together in advance to coordinate on a lot of aspects of the trial infrastructure, we can actually share a control arm. If we jointly choose a contract research organization that's going to go out and help us recruit patients, and if we jointly choose an IT provider, and IT systems, we can silo off our individual information about the actual experimental therapies we're studying, and share a control group of patients.  Now, without doing anything else, we have just gone from needing 160 patients in total for us both to get statistical significance, to needing 120 patients. The sample size has decreased. We're seeing efficiencies, especially in uncommon cancer where it's often hard to find these patients; 40 percent of cancer trials never fully enroll.  Then, we can layer on top of that setup what we call Bayesian adaptive randomization. That's a mouthful, but what that means is that we're actually using Bayesian statistics that have been pre-specified for this trial, to figure out how to efficiently assign patients to different arms of the trial. Go back to my example from before. We have patients with a certain tumor type, and we learned that they are doing incredibly well on your therapy, on therapy B, based on interim analysis, so about once a month we're going to actually look at the data, and see how patients are progressing.  We say, "Wow, patients of this type are doing really well in Brian's therapy." We can use our pre-specified algorithm to now preferentially assign that type of patient to your arm of the trial. Patients love this. As the trial progresses, patients are not only being used efficiently, because of the shared control arm component of the trial design, but we've also got the patients that are coming in being preferentially assigned to the treatment arm of the trial they're most likely to benefit from.  Kenny: 	So we've gotten efficiencies, we've got better patient outcomes, those are two great things. What are some of the other benefits that emerge from using the adaptive platform trials? Stern: 	So thinking back to my mother’s experience, the other thing we get is faster information on what won't work. This is quite important and something we don't talk about enough. What Bayesian adaptive platform trials allow us to do, as we talk about trial arm stopping, and graduation. Graduation means that we learn very quickly that a trial's very effective, and we can move that drug onto the next phase. Stopping means that we also learn efficiently if a particular therapy isn't going to work for a group of patients. Surely it's desirable to stop researching that drug in that group of patients if we have a very good statistical signal that it's unlikely to help them.  Kenny:  Let's dig into some of the business challenges. I was fascinated reading about just how many people are involved in this, and some of the really difficult business challenges that they faced in trying to get the trial up and running. Can you talk a little bit about that?  Stern:  If you read between the lines in the case, what you'll see is that putting together just this one trial involved over 130 oncologists, pathologists, radiologists, and statisticians. This is a massively collaborative effort... Kenny: 	There was some real entrepreneurial thinking needed about how you fund something like this. They came up with some very interesting ways on how to fund it.  Stern:  One of the benefits of an adaptive platform trial is that we set up the infrastructure once and then can continue to add experimental therapies to the trial. But that's costly, because we're building infrastructure for something that hopefully will last for many years, if not decades, until we have good treatments for glioblastoma. What that means is the upfront costs are massive.  We have a lot of traditional financing options, looking at things like asking pharmaceutical companies, who typically fund clinical research anyhow, to pay for individual arms of the trial. But, the upfront costs are still quite an obstacle. In this case, the folks running the trial decided to start a foundation. The foundation is called, "The Global Coalition for Adaptive Research." Through this foundation, they were able to start negotiating relationships with contract research organizations, and only then, start to approach pharmaceutical companies and other cancer research groups to think about how they might want to be involved financially.  Kenny: 	I was particularly interested in the notion of them becoming a health care provider. That was really innovative.  Stern:  While there's this really daunting upfront challenge in financing, there are a number of new opportunities created here as well. One of the insights that Brian Alexander has had in thinking about this is why not provide all of the health care for glioblastoma patients. We've got folks coming in anyhow, they're going to be seeing experts in both medical and radiation oncology anyhow, why not just outsource all of the care for those patients to one of these trial sites and try to capture some of the value for patients and providers in that way. So that was one idea.  The cost of doing a trial in glioblastoma for other experimental cancer therapies will go down once this platform exists. You could also get really creative—this is HBS, after all—with thinking about other things that we might do. Just one example is that there are a lot of small biotechnology companies that have only one or two experimental cancer drugs, and they've got resources from their funders, typically venture capitalists, to run maybe only clinical trials in one type of cancer.  Now, because we have this foundation behind this research platform, the foundation can approach some of these small biotech companies and say, "Hey look, we think your drug might be interesting to study in glioblastoma. Why don't you give it to us and we'll pay for that arm of the trial. We'll study your drug and if it turns out this drug is effective, we'll have some sort of royalty sharing agreement on the back end." Suddenly, the foundation is able to take on some of the risk and also have a piece of the action if it turns out that these drugs are effective.  Kenny: 	Have you discussed this case in class?  Stern: 	I have. We've had a couple of events—we were able to discuss this at Boston's Hub Week event... And then I also discussed this with a group of HBS Healthcare Alumni a couple of months ago. They loved it. It's interesting t hatthe folks who've worked in pharma have two reactions, very rapidly. The first reaction is, "Wow, this makes so much sense." The second reaction that follows immediately is, "I don't know if these companies will ever go for this." People who have seen what clinical research management looks like right away say, "Oh, this is going to really freak people out, this is so different than how we've been doing clinical research up until now."  I think they're right, but I think that we're all going to be positively surprised.  Kenny: 	Thanks so much for joining us today.  Stern: 	Thanks so much for having me Brian.  Kenny: 	If you enjoyed this episode of Cold Call, please subscribe on iTunes for more cases like this one, and while you're there, please write a review. You can find the adaptive platform trials case in the HBS case collection at hbr.org. I'm your, host Brian Kenny, and you've been listening to Cold Call.  Interview transcript edited for length and clarity. Interview recorded January 26, 2018. 